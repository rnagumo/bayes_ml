{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "pytorch",
   "display_name": "pytorch"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import pixyz.distributions as pxd\n",
    "import pixyz.losses as pxl\n",
    "import pixyz.models as pxm\n",
    "import pixyz.utils as pxu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorRNN(pxd.Deterministic):\n",
    "    def __init__(self, z_dim, u_dim, h_dim):\n",
    "        super().__init__(cond_var=[\"z\", \"u\", \"h_prev\"], var=[\"h\"])\n",
    "\n",
    "        self.rnn_cell = nn.RNNCell(z_dim + u_dim, h_dim)\n",
    "\n",
    "    def forward(self, z, u, h_prev):\n",
    "        h = self.rnn_cell(torch.cat([z, u], dim=-1), h_prev)\n",
    "        return {\"h\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(h|z,u,h_{prev})\nNetwork architecture:\n  GeneratorRNN(\n    name=p, distribution_name=Deterministic,\n    var=['h'], cond_var=['z', 'u', 'h_prev'], input_var=['z', 'u', 'h_prev'], features_shape=torch.Size([])\n    (rnn_cell): RNNCell(5, 4)\n  )\n"
    }
   ],
   "source": [
    "print(GeneratorRNN(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(pxd.Bernoulli):\n",
    "    # TODO: `h_prev` is not updated.\n",
    "    def __init__(self, h_dim, x_dim):\n",
    "        super().__init__(cond_var=[\"h\"], var=[\"x\"])\n",
    "\n",
    "        self.fc1 = nn.Linear(h_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, x_dim)\n",
    "\n",
    "    def forward(self, h):\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        probs = torch.sigmoid(self.fc3(h))\n",
    "        return {\"probs\": probs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(x|h)\nNetwork architecture:\n  Generator(\n    name=p, distribution_name=Bernoulli,\n    var=['x'], cond_var=['h'], input_var=['h'], features_shape=torch.Size([])\n    (fc1): Linear(in_features=2, out_features=512, bias=True)\n    (fc2): Linear(in_features=512, out_features=256, bias=True)\n    (fc3): Linear(in_features=256, out_features=3, bias=True)\n  )\n"
    }
   ],
   "source": [
    "print(Generator(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceRNN(pxd.Deterministic):\n",
    "    def __init__(self, x_dim, z_dim):\n",
    "        super().__init__(cond_var=[\"x\"], var=[\"h_v\"])\n",
    "\n",
    "        self.rnn = nn.RNN(x_dim, z_dim * 2)\n",
    "        self.h0 = nn.Parameter(torch.zeros(1, 1, z_dim * 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = self.h0.expand(1, x.size(1), self.h0.size(2)).contiguous()\n",
    "        h, _ = self.rnn(x, h0)\n",
    "        return {\"h_v\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Distribution:\n  p(h_{v}|x)\nNetwork architecture:\n  InferenceRNN(\n    name=p, distribution_name=Deterministic,\n    var=['h_v'], cond_var=['x'], input_var=['x'], features_shape=torch.Size([])\n    (rnn): RNN(2, 6)\n  )\n"
    }
   ],
   "source": [
    "print(InferenceRNN(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(pxd.Normal):\n",
    "    def __init__(self):\n",
    "        super().__init__(cond_var=[\"h_v\"], var=[\"z\"])\n",
    "\n",
    "    def forward(self, h_v):\n",
    "        loc = h_v[:, :h_v.size(1) // 2]\n",
    "        scale = h_v[:, h_v.size(1) // 2:] ** 2\n",
    "        return {\"loc\": loc, \"scale\": scale}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 2\n",
    "h_dim = 4\n",
    "x_dim = 10\n",
    "u_dim = x_dim\n",
    "\n",
    "prior = pxd.Normal(loc=torch.tensor(0.), scale=torch.tensor(1.),\n",
    "                    var=[\"z\"], features_shape=torch.Size([z_dim])).to(device)\n",
    "grnn = GeneratorRNN(z_dim, u_dim, h_dim).to(device)\n",
    "decoder = Generator(h_dim, x_dim).to(device)\n",
    "irnn = InferenceRNN(x_dim, z_dim).to(device)\n",
    "encoder = Inference().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": "$\\displaystyle - \\mathbb{E}_{p(h,z|u,h_{prev},h_{v})} \\left[\\log p(x|h) \\right]$",
      "text/plain": "<IPython.core.display.Math object>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = pxl.CrossEntropy(grnn * encoder, decoder)  #.expectation(grnn)\n",
    "pxu.print_latex(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Normal(\n  name=p, distribution_name=Normal,\n  var=['z'], cond_var=[], input_var=[], features_shape=torch.Size([2])\n  (loc): torch.Size([1, 2])\n  (scale): torch.Size([1, 2])\n)\nGeneratorRNN(\n  name=p, distribution_name=Deterministic,\n  var=['h'], cond_var=['z', 'u', 'h_prev'], input_var=['z', 'u', 'h_prev'], features_shape=torch.Size([])\n  (rnn_cell): RNNCell(12, 4)\n)\nGenerator(\n  name=p, distribution_name=Bernoulli,\n  var=['x'], cond_var=['h'], input_var=['h'], features_shape=torch.Size([])\n  (fc1): Linear(in_features=4, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=256, bias=True)\n  (fc3): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(decoder * grnn * prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 1\n",
    "\n",
    "data = {\n",
    "    \"h_prev\": torch.zeros(minibatch_size, h_dim).to(device),\n",
    "    \"u\": torch.zeros(minibatch_size, x_dim).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (decoder * grnn * prior).sample(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'h_prev': tensor([[0., 0., 0., 0.]]),\n 'u': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n 'z': tensor([[-0.5331, -0.0121]]),\n 'h': tensor([[-0.7125,  0.5394, -0.1833,  0.3985]], grad_fn=<TanhBackward>),\n 'x': tensor([[1., 1., 1., 0., 0., 0., 1., 1., 0., 0.]])}"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4982, 0.5154, 0.5164, 0.5042, 0.5099, 0.5293, 0.5166, 0.4790, 0.5049,\n         0.5201]], grad_fn=<SigmoidBackward>)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.sample_mean({\"h\": sample[\"h\"]})"
   ]
  }
 ]
}